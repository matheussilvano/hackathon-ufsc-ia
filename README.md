# Cognita Suite - Hackathon AI Challenge SECCOM UFSC

![Status](https://img.shields.io/badge/status-conclu√≠do-brightgreen)
![Evento](https://img.shields.io/badge/evento-Hackathon%20AI%20Challenge-blue)
![Trilha](https://img.shields.io/badge/trilha-Educa√ß√£o-9cf)
![Frontend](https://img.shields.io/badge/frontend-HTML%20|%20CSS%20|%20JS-orange)
![Backend](https://img.shields.io/badge/backend-FastAPI-darkgreen)
![IA](https://img.shields.io/badge/IA-Google%20Gemini%20|%20LangChain-purple)
![Vector DB](https://img.shields.io/badge/Vector%20DB-ChromaDB-blueviolet)

O **Cognita Suite** √© uma aplica√ß√£o web desenvolvida para a trilha de Educa√ß√£o do **Hackathon AI Challenge da SECCOM UFSC**. A su√≠te visa potencializar os estudos de alunos, oferecendo ferramentas inteligentes para corre√ß√£o de reda√ß√µes e consulta a materiais de estudo, tudo impulsionado por modelos de linguagem de ponta.

<img width="1367" height="677" alt="image" src="https://github.com/user-attachments/assets/3eafcab0-9556-462a-800d-7b021ce6c3b3" />


## üìö Sum√°rio
1. [Sobre o Projeto](#1-sobre-o-projeto)
2. [M√≥dulos da Su√≠te](#2-m√≥dulos-da-su√≠te)
    - [M√≥dulo Grifo (Corretor de Reda√ß√µes)](#grifo---corretor-de-reda√ß√µes)
    - [M√≥dulo Sinapse (Base de Conhecimento com RAG)](#sinapse---base-de-conhecimento-com-rag)
3. [üß† Detalhes da Implementa√ß√£o de IA](#3-detalhes-da-implementa√ß√£o-de-ia)
    - [IA do Grifo: Prompt Engineering e An√°lise Calibrada](#ia-do-grifo-prompt-engineering-e-an√°lise-calibrada)
    - [IA do Sinapse: Arquitetura RAG com LangChain](#ia-do-sinapse-arquitetura-rag-com-langchain)
4. [üõ†Ô∏è Stack Tecnol√≥gica](#4-stack-tecnol√≥gica)
5. [üöÄ Como Executar o Projeto](#5-como-executar-o-projeto)
6. [üë®‚Äçüíª Autor](#6-autor)

## 1. Sobre o Projeto
A Cognita Suite √© composta por dois m√≥dulos principais integrados em uma interface web fluida e moderna: **Grifo**, um corretor de reda√ß√µes para os vestibulares do ENEM e da UFSC, e **Sinapse**, um sistema de perguntas e respostas que transforma documentos de estudo em uma base de conhecimento interativa.

A aplica√ß√£o foi constru√≠da com um frontend em HTML, CSS e JavaScript puros, que se comunica com um backend robusto em **FastAPI (Python)**, onde toda a l√≥gica de Intelig√™ncia Artificial √© processada.

## 2. M√≥dulos da Su√≠te

### Grifo - Corretor de Reda√ß√µes
**Grifo** √© uma ferramenta de IA projetada para analisar e avaliar reda√ß√µes nos moldes dos vestibulares mais importantes de Santa Catarina e do Brasil.

- **M√∫ltiplos Formatos de Entrada:** Aceita o envio de reda√ß√µes tanto por **upload de imagem** (utilizando Google Cloud Vision para OCR) quanto por **texto digitado**.
- **Modelos de Corre√ß√£o:** Oferece corre√ß√£o especializada para o **ENEM**, baseada nas 5 compet√™ncias, e para a **UFSC**, avaliando os 4 crit√©rios da banca e adaptando-se ao g√™nero textual solicitado (conto, disserta√ß√£o, etc.).
- **Feedback Detalhado:** Fornece uma an√°lise geral, nota final e um feedback construtivo para cada crit√©rio de avalia√ß√£o, ajudando o aluno a identificar pontos fortes e fracos.
- **Hist√≥rico Local:** Salva as corre√ß√µes no `localStorage` do navegador, permitindo que o usu√°rio acesse seu hist√≥rico de desempenho.

<img width="1367" height="677" alt="image" src="https://github.com/user-attachments/assets/f7dce579-a68b-464d-ad7a-9591d82a9a85" />


### Sinapse - Base de Conhecimento com RAG
**Sinapse** √© um assistente de estudos que utiliza a t√©cnica de **Retrieval-Augmented Generation (RAG)** para responder perguntas com base em documentos fornecidos pelo usu√°rio.

- **Upload de Documentos:** O usu√°rio pode fazer upload de materiais de estudo nos formatos **PDF** e **PPTX**.
- **Base de Conhecimento Persistente:** Os documentos s√£o processados, vetorizados e armazenados em uma base de dados vetorial **ChromaDB** local, criando uma base de conhecimento duradoura.
- **Consultas em Linguagem Natural:** O aluno pode fazer perguntas sobre o conte√∫do dos documentos, e a IA buscar√° as informa√ß√µes mais relevantes para formular uma resposta precisa e contextualizada.

## 3. Detalhes da Implementa√ß√£o de IA
O cora√ß√£o do projeto est√° no uso estrat√©gico de modelos generativos da fam√≠lia **Google Gemini**, orquestrados de maneiras distintas para cada m√≥dulo.

<img width="1367" height="677" alt="image" src="https://github.com/user-attachments/assets/b28defde-6c23-4719-9e35-8544b7cdb68f" />


### IA do Grifo: Prompt Engineering e An√°lise Calibrada
Para o m√≥dulo de corre√ß√£o de reda√ß√µes, a precis√£o e a justi√ßa da avalia√ß√£o eram cruciais. A t√©cnica central utilizada foi o **Prompt Engineering Avan√ßado**.

- **Modelo Utilizado:** `Gemini-2.5-pro`.
- **Persona e Calibragem (One-Shot Learning):** O prompt instrui o modelo a atuar como um "avaliador treinado e calibrado" da banca espec√≠fica (ENEM ou UFSC). Para o ENEM, o prompt inclui um exemplo completo de uma reda√ß√£o nota 900, com a pontua√ß√£o detalhada por compet√™ncia. Isso funciona como um exemplo de *one-shot learning*, ancorando o julgamento do modelo a um padr√£o de refer√™ncia realista e de alta qualidade.
- **Diretiva Cr√≠tica para OCR:** Uma inova√ß√£o chave no prompt √© a "Diretiva Cr√≠tica" que instrui o modelo a **distinguir erros gramaticais reais de artefatos de digitaliza√ß√£o (OCR)**. O modelo √© orientado a presumir a favor do aluno em caso de d√∫vida, focando em erros estruturais em vez de penalizar pequenas falhas de extra√ß√£o de texto.
- **Sa√≠da Estruturada:** A API do Gemini √© chamada com o par√¢metro `response_mime_type="application/json"`. Isso for√ßa o modelo a gerar sua resposta diretamente no formato JSON especificado no prompt, garantindo uma integra√ß√£o robusta e sem falhas com o frontend, eliminando a necessidade de parsing de texto.

### IA do Sinapse: Arquitetura RAG com LangChain
O m√≥dulo Sinapse implementa uma pipeline cl√°ssica e eficiente de **Retrieval-Augmented Generation (RAG)**, utilizando o framework **LangChain** para orquestrar todas as etapas.

- **Modelos Utilizados:**
    - **Embeddings:** `models/embedding-001` para transformar os textos em vetores num√©ricos.
    - **Gera√ß√£o de Resposta:** `Gemini-2.5-pro` para sintetizar a resposta final.
- **Pipeline RAG:**
    1.  **Carregamento e Divis√£o:** Documentos (PDF, PPTX) s√£o carregados com `PyPDFLoader` ou `UnstructuredPowerPointLoader` e divididos em peda√ßos menores (*chunks*) com `RecursiveCharacterTextSplitter` para otimizar a busca.
    2.  **Vetoriza√ß√£o e Armazenamento:** Cada *chunk* √© convertido em um vetor de embeddings pelo modelo `embedding-001` e armazenado no **ChromaDB**. O uso de um cliente persistente (`PersistentClient`) garante que a base de conhecimento n√£o seja perdida ao reiniciar a API.
    3.  **Recupera√ß√£o (Retrieval):** Quando o usu√°rio faz uma pergunta, ela tamb√©m √© vetorizada. O ChromaDB realiza uma busca por similaridade de cosseno para encontrar os *chunks* de texto mais relevantes para a pergunta.
    4.  **S√≠ntese (Generation):** Os *chunks* recuperados s√£o inseridos em um prompt final, juntamente com a pergunta original. O modelo `Gemini-2.5-pro` recebe esse contexto e √© instru√≠do a responder √† pergunta baseando-se **estritamente** nas informa√ß√µes fornecidas, evitando alucina√ß√µes.
- **Orquestra√ß√£o com LangChain:** O LangChain √© utilizado para conectar todos esses componentes de forma coesa, desde a cria√ß√£o do retriever (`vector_store.as_retriever()`) at√© a montagem da cadeia de recupera√ß√£o final (`create_retrieval_chain`).

## 4. Stack Tecnol√≥gica
- **Frontend:** HTML5, CSS3, JavaScript (Vanilla)
- **Backend:** Python 3.10+, FastAPI
- **Intelig√™ncia Artificial:**
    - **Modelos:** Google Gemini 1.5 Pro, Google Embedding-001
    - **Frameworks:** LangChain, Google Generative AI for Python
    - **OCR:** Google Cloud Vision API
- **Banco de Dados Vetorial:** ChromaDB (com persist√™ncia local)
- **Servidor (Desenvolvimento):** Uvicorn

## 5. Como Executar o Projeto

#### Pr√©-requisitos
- Python 3.9+
- Um navegador web moderno (Chrome, Firefox, etc.)
- Chaves de API para o **Google AI (Gemini)** e credenciais para o **Google Cloud Vision**.

#### 1. Configura√ß√£o do Backend
```bash
# 1. Clone o reposit√≥rio
git clone <URL_DO_REPOSITORIO>
cd <NOME_DA_PASTA>

# 2. Crie e ative um ambiente virtual
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate

# 3. Instale as depend√™ncias
pip install -r requirements.txt # (Crie um requirements.txt com as bibliotecas dos arquivos .py)

# 4. Configure as vari√°veis de ambiente
# Crie um arquivo .env na raiz do projeto ou configure as vari√°veis no seu sistema
export GEMINI_API_KEY="SUA_CHAVE_API_GEMINI"
export GOOGLE_APPLICATION_CREDENTIALS="/caminho/para/seu/arquivo-de-credenciais.json"

# 5. Rode o servidor FastAPI
uvicorn main:app --reload

A API estar√° rodando em http://127.0.0.1:8000.
```

### 2. Configura√ß√£o do Frontend
```bash
Abra o arquivo index.html diretamente no seu navegador.

Na interface da aplica√ß√£o, no canto superior direito, insira a URL da sua API local (http://127.0.0.1:8000) no campo "URL da API" e clique em "Salvar".

A aplica√ß√£o est√° pronta para ser usada!
```

## 6. Autores
Desenvolvido por Matheus Silvano, Bernardo Thomas e Igor do Carmo
